# layers: [50, 50]
# layers: [200, 200, 200, 200, 200]
layers: [128, 128, 128, 128, 128, 128, 128]
activation: relu
